# Indian-Language-Understanding-using-indicBERT

Assignment 2 (Language - Hindi)

Name - Rahul Kumar
Roll No. - 21111069
Prog. - Mtech CSE
Mail - rahulkumar21@iitk.ac.in
Contact - 7761937143


Python version used - 3.8.12

*** NOTE *** 
1. Make sure you are connected with internet. (If you are running on cse server run authenticator.py file to bypass the firewall)
2. Make sure glove_vec.pickle file is downloaded in the utils folder. https://drive.google.com/drive/folders/1jHs1KqWFghTJ9OdXj1fdDP5FiVaQMDxm?usp=sharing
3. Put every data inside the data folder (Download from here - 
    a. Pretrained-word vectors - https://www.cfilt.iitb.ac.in/~diptesh/embeddings/monolingual/non-contextual/
    b. Word similarity datasets - https://drive.google.com/drive/folders/1VovzSE1-zXH0bKCar2M8peL4-62BSlZJ?usp=sharing
    c. NER datasets - https://drive.google.com/file/d/1S5TOqIC37dxWCeQbA9VpplXOGAB7cIMV/view?usp=sharing
    d. Hindi Corpora - https://indicnlp.ai4bharat.org/corpora/



This folder contains following directories and files 
1. data - contains all the data used in this assignment 2
    a.  Pretrained-word vectors- Used 50d pretrained word vectors.
    b.  Word similarity datasets - contains a set of pairs of two hindi words
    c.  NER datasets - contains list of hindi words and their tags.
    d. Hindi Corpora - 1.8 B tokens hindi corpora. (Size - approx 22 GB)
2. utils - It contains the necessary file which takes time to build like glove_vec
3. output - a folder contains all the generated outputs for all 3 questions.
4. q1.py - This is file for first question in the assignment which majorily doing the task of word similarity on different thresholds.
5. q2.py - Building NER model for Hindi language.
6. q3.py - This file is for finding all the most frequent char, word and syllable of unigrams, bigrams, trigrams, quadrigrams.
7. run.sh - This is the file that contains all the variable parameters mentioned in the below section.
8. Makefile - There are two commands in the makefile one is "install", "run"
    a.  make install - install all the required packages and download the drive files (please follow the drive link if you're not able to download from the make install)
    b.  make run - will run the whole assignments 

*** run.sh is the top-level script that runs the entire assignment. ***

### To run the entire assignment, go to home directory where this README file is there and use following command
##  $ make install 
##  $ make run 

These are the variables that I'm passing as an arguments in the program. [ change accordingly ]

1. top_k = 5 - top k documents will be retrieved
2. corpus = "./data/english-corpora/" - Corpus path
3. vocab_path = './utils/vocab_doc_wise_stemming.npy' - This is the vocab file path (in numpy format) document wise which contains a dictionary where keys are docID and values are the vocab present in that documents which I have already generated required in all 3 IR systems. This takes time to build so if you still want, you can build your own. There is one flag named vocab_flag. Put this variable equal to 1. Otherwise you can use my generated vocab_doc_wise_stemming.npy present in the utils folder.
4. postings_path="./utils/postings_list.pkl" - This is the postings list already generated by myself required in all 3 IR systems. This also takes time to build if you want to build put postings_flag=1.
5. doc_vector_path='./utils/sparse_matrix_doc_vectors.npz' - This is Doc vectors file required for TF-IDF system. This also takes time to build so if you want to build put vector_flag=1.
6. query_file='./data/query.txt' - This is the query path you need to give if you want to try my assignment on someone else query.
7. out_folder='./output/' - This is the output folder path.
8. vocab_flag=0 - This is for creating own vocab_doc_wise_stemming
9. postings_flag=0 - This is for creating own postings lists
10. vector_flag=0 - This is for creating own docments vectors.


#### Preprocessing #####################################

1. Text is splitted by '\t' first.
2. Remove extra spaces
3. Tokenize the strings
4. Remove Punctuations from tokenize words
5. Remove Number
6. Remove Double quotations from tokens
7. Replace URL with url tag
8. Remove ascents from string using decode like A&deg;
9. Split camelCase word into 'camel' and 'Case'
10. Remove number from token


#### Boolean IR System #################################

This system takes an average 0.0032 sec to process one query.

1. Tokenize the query
2. Convert infix query expression to postfix query expression using stack approach
        a. Check if the given expression is balanced or not
        b. Check is there any extra parenthesis in the expression
3. Processing two operator only in the query **\&**(and) , **\|** (or) and **\~**(negation) and giving higeher precedence to the former
4. Using **snowball_stemmer** as a stemmer algorithm to find the stem word in the given query
5. Generate binary vector based on document size and consider negation sign as well while processing
6. Find document which contains the query word using **find_matched_doc** function and return a binary vector that shows which document contains that word
7. Remove stop words from query

#### TF-IDF IR System ###################################

This system takes an average 22 sec to process one query.

1. Tokenize the query first and remove the stopwords from the query and also remove nonASCII character
2. Find the query vector where each dimension represents freq. of token present in the query
3. For fast query processing, I have created one doc_vectors which is of shape (doc_size, total vocab) previously and saved their vectors in sparse_matrix_doc_vectors.npz
4. In doc vectors, rows represent all the documents and columns represent all the vocab present in all the documents 
5. Doc vectors are sparse matrix inorder to save space I used scipy.sparse.matrix to save all doc vectors.
6. Return top-k documents only.
7. I have also tried to prepare champion lists that is nothing but for each vocab in the documents find the rank of documents corresponding to them. But
    it was taking too much space more than 24 GB) and also taking more than 24 hrs to prepare those lists. But I have provided the code for the same.
8. While calculating similarity score we don't need to normalize the query vector as even without normalization, product of V_q and v_d are much higher.

#### BM-25 IR System ####################################

This system takes an average 0.018 sec to process one query.

1. Tokenize the query into tokens and remove the stop words and also remove if there's any non-ascii characters
2. Get local weight by modified term frequency formula $$\frac{(k_1+1)tf_d}{k_1(1-b+b\frac{L_d}{L_avg}) + tf_d}$$
3. Get global weight by inverse doc frequency as the priors aren't given by given formula $$\log \frac{n}{df_t}$$
4. Get RSVd score using below formula and based on this score, select top k documents $$RSVd = \sum_{\forall t \in q} \left(\log \frac{n}{df_t}\right) . \frac{(k_1+1)tf_d}{k_1(1-b+b\frac{L_d}{L_avg}) + tf_d}$$


# Incase you face any issue in running the code, just let me know here - rahulkumar21@iitk.ac.in
